{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c966c05-cb8b-40fa-8b5c-20c67036a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b761491-3abb-415c-846c-b8434d78ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ash/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ash/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/ash/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/ash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ash/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba5bfdd-086f-44f0-86b5-05b431bcd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read a PDF file\n",
    "pdf_path = \"/home/ash/Downloads/git/DSBDA/exp7/sample1.pdf\"  # path to your PDF file\n",
    "pdf_reader = PyPDF2.PdfReader(open(pdf_path, 'rb'))\n",
    "\n",
    "# Extract text from all pages\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8853f4f1-b94a-451d-a85e-3558382d2372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smallpdf\n",
      "Digital Documents—All In One Place\n",
      "Access Files Anytime, Anywhere Enhance Documents in One Click \n",
      "Collaborate With Others With the new Smallpdf experience, you can \n",
      "freely upload, organize, and share digital \n",
      "documents. When you enable the ‘Storage’ \n",
      "option, we’ll also store all processed files here. \n",
      "You can access files stored on Smallpdf from \n",
      "your computer, phone, or tablet. We’ll also \n",
      "sync files from the Smallpdf Mobile App to our \n",
      "online portalWhen you right-click on a file, we’ll present \n",
      "you with an array of options to convert, \n",
      "compress, or modify it. \n",
      "Forget mundane administrative tasks. With \n",
      "Smallpdf, you can request e-signatures, send \n",
      "large files, or even enable the Smallpdf G Suite \n",
      "App for your entire organization. Ready to take document management to the next level? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "018a5736-c8ef-417a-878f-460c1428ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a39e8d8c-d5c8-4adc-a69a-2e9082fc9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef9eab44-ed3e-451f-9e5a-f82170b71bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6961aaf-87ab-41b5-b8ba-84416ba75487",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(word) for word in filtered_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "668c8411-4c3d-40cb-8ead-4e3c44611807",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6298ffe5-5e68-4851-bbd7-83424fb55067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "smallpdf  0.338062\n",
      "you       0.338062\n",
      "the       0.281718\n",
      "files     0.281718\n",
      "to        0.281718\n",
      "...            ...\n",
      "sync      0.056344\n",
      "stored    0.056344\n",
      "upload    0.056344\n",
      "welcome   0.056344\n",
      "when      0.056344\n",
      "\n",
      "[82 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([text])  # wrap text in list if single document\n",
    "\n",
    "# To display as DataFrame\n",
    "import pandas as pd\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df_tfidf.T.sort_values(by=0, ascending=False))  # sorted by importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c0452-5710-4d35-9f6a-2e5b21a01a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
